{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection Notebook\n",
    "\n",
    "This notebook outlines the data collection carried out for the project. As it is supplementary to the main project, code is not heavily commented. This notebook instead aims to provide a brief overview of the steps taken to create ```cleaned_intensity_dataset.csv```, which is analysed in the project.\n",
    "\n",
    "First, I loaded ```2021_politicians_data.csv```, a section of the Twitter Parliamentarian Database (Vliet et al., 2020), selected for UK MP's, and removed unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>constituency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>diane abbott</td>\n",
       "      <td>Labour</td>\n",
       "      <td>Hackney North and Stoke Newington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>debbie abrahams</td>\n",
       "      <td>Labour</td>\n",
       "      <td>Oldham East and Saddleworth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>nigel adams</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Selby and Ainsty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>bim afolami</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Hitchin and Harpenden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>adam afriyie</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Windsor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name         party                       constituency\n",
       "540     diane abbott        Labour  Hackney North and Stoke Newington\n",
       "541  debbie abrahams        Labour        Oldham East and Saddleworth\n",
       "542      nigel adams  Conservative                   Selby and Ainsty\n",
       "543      bim afolami  Conservative              Hitchin and Harpenden\n",
       "544     adam afriyie  Conservative                            Windsor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/mp_data/2021_politicians_data.csv\")\n",
    "df_uk = df[df['country'] == 'United Kingdom']\n",
    "\n",
    "df_uk = df_uk.drop(columns=['pol_group_id', 'name_link', 'party_pol_group_id', \n",
    "                            'uid', 'mp_party_id', 'legislative_period_id', \n",
    "                            'country_id', 'date_of_inactivity', 'scraper_url',\n",
    "                            'function', 'region', 'country', 'member_id', 'party_id', 'chamber'])\n",
    "df_uk.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I mapped MP names to usernames from a csv I created containing MP names, constituencies and usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaron bell</td>\n",
       "      <td>@AaronBell4NUL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abena oppong-asare</td>\n",
       "      <td>@abenaopp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam afriyie</td>\n",
       "      <td>@AdamAfriyie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afzal khan</td>\n",
       "      <td>@Afzal4Gorton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alan brown</td>\n",
       "      <td>@AlanBrownSNP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name        Username\n",
       "0          aaron bell  @AaronBell4NUL\n",
       "1  abena oppong-asare       @abenaopp\n",
       "2        adam afriyie    @AdamAfriyie\n",
       "3          afzal khan   @Afzal4Gorton\n",
       "4          alan brown   @AlanBrownSNP"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "username_name_df = pd.read_csv(\"data/mp_data/name_username_constituency.csv\")\n",
    "\n",
    "username_name_df['Name'] = username_name_df['Name'].apply(lambda x: str(x).lower())\n",
    "\n",
    "username_name_df.drop(columns=['Constituency'], inplace=True)\n",
    "username_name_df = username_name_df.rename(columns={'Screen_Name': 'Username'})\n",
    "username_name_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>party</th>\n",
       "      <th>constituency</th>\n",
       "      <th>Username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diane abbott</td>\n",
       "      <td>Labour</td>\n",
       "      <td>Hackney North and Stoke Newington</td>\n",
       "      <td>@HackneyAbbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debbie abrahams</td>\n",
       "      <td>Labour</td>\n",
       "      <td>Oldham East and Saddleworth</td>\n",
       "      <td>@Debbie_abrahams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nigel adams</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Selby and Ainsty</td>\n",
       "      <td>@nadams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bim afolami</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Hitchin and Harpenden</td>\n",
       "      <td>@BimAfolami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam afriyie</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>Windsor</td>\n",
       "      <td>@AdamAfriyie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name         party                       constituency  \\\n",
       "0     diane abbott        Labour  Hackney North and Stoke Newington   \n",
       "1  debbie abrahams        Labour        Oldham East and Saddleworth   \n",
       "2      nigel adams  Conservative                   Selby and Ainsty   \n",
       "3      bim afolami  Conservative              Hitchin and Harpenden   \n",
       "4     adam afriyie  Conservative                            Windsor   \n",
       "\n",
       "           Username  \n",
       "0    @HackneyAbbott  \n",
       "1  @Debbie_abrahams  \n",
       "2           @nadams  \n",
       "3       @BimAfolami  \n",
       "4      @AdamAfriyie  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(df_uk, username_name_df, left_on='name', right_on='Name')\n",
    "merged_df.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then used a web scraper, Nitter, to collect as many tweets as possible from each MP (denoted by ```number=-1```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ntscraper import Nitter\n",
    "\n",
    "scraper = Nitter()\n",
    "def scrape_tweets(username):\n",
    "    try:\n",
    "        # Use the scraper to get the tweets\n",
    "        tweets = scraper.get_tweets(username[1:], mode='user', number=-1)\n",
    "        # Process the tweets to extract the desired information\n",
    "        # For example, return the count of tweets or the tweets themselves\n",
    "        return tweets\n",
    "    except Exception as e:\n",
    "        # Handle exceptions, e.g., user not found or rate limits exceeded\n",
    "        return None\n",
    "    \n",
    "merged_df['tweets'] = merged_df['Username'].apply(scrape_tweets)\n",
    "\n",
    "merged_df.to_csv('scraped_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the scraper failed to find the username of an MP. To overcome this limitation, I iteratively ran the scraper over rows where data was not collected, until iterations no longer resulted in fewer gaps in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('scraped_dataset.csv')\n",
    "\n",
    "# Check for NaN or empty tweets\n",
    "failed_scraping = merged_df['tweets'].isna() | (merged_df['tweets'] == \"{'tweets': [], 'threads': []}\")\n",
    "\n",
    "previous_df_len = 100 \n",
    "while True:\n",
    "    failed_df = merged_df[failed_scraping]\n",
    "    df_len = len(failed_df)\n",
    "    if df_len == previous_df_len:\n",
    "        break\n",
    "    previous_df_len = df_len\n",
    "\n",
    "    failed_df['tweets'] = failed_df['Username'].apply(scrape_tweets)\n",
    "\n",
    "    merged_df.loc[failed_scraping, 'tweets'] = failed_df['tweets']\n",
    "    merged_df = merged_df.drop(columns=['member_id', 'party_id', 'chamber'])\n",
    "\n",
    "    merged_df.to_csv('data/scraper_results/scraped_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I separated individual tweets into separate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns = list(merged_df.columns) + ['text', 'date', 'is_retweet', 'stats']\n",
    "rows_list = []\n",
    "\n",
    "for index, row in merged_df.iterrows():\n",
    "    mp_info = row.to_dict()\n",
    "    \n",
    "    tweets = dict(row['tweets']).get('tweets', []) if pd.notna(row['tweets']) else []\n",
    "    \n",
    "    for tweet in tweets:\n",
    "        tweet_info = {\n",
    "            'text': tweet['text'],\n",
    "            'date': tweet['date'],\n",
    "            'is_retweet': tweet['is-retweet'],\n",
    "            'stats': tweet['stats']\n",
    "        }\n",
    "        \n",
    "        new_row = {**mp_info, **tweet_info}\n",
    "        \n",
    "        rows_list.append(new_row)\n",
    "\n",
    "politician_tweet_df = pd.DataFrame(rows_list, columns=columns)\n",
    "politician_tweet_df = politician_tweet_df.drop(columns=[\"tweets\"])\n",
    "\n",
    "politician_tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I processed each tweet to remove unwanted text like hashtags, hyperlinks and emojis, and droppped retweets from the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supplementary_code import process_df_text\n",
    "\n",
    "politician_tweet_df = process_df_text(politician_tweet_df, 'text') # Remove hashtags, hyperlinks, emojis.\n",
    "politician_tweet_df = politician_tweet_df[politician_tweet_df['is_retweet'] == False] # Filter retweets.\n",
    "politician_tweet_df = politician_tweet_df.dropna() # Remove missing values.\n",
    "politician_tweet_df.reset_index()\n",
    "\n",
    "print(len(politician_tweet_df))\n",
    "politician_tweet_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I passed each tweet through each model to obtain emotion intensity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Took about 200 minutes to run on an M2 Macbook Air. On a CPU it will likely take significantly longer.\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=1)\n",
    "device = torch.device(\"mps\") # I used mps as I use an Apple device. Windows users should use Cuda if available, or the CPU if not.\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def predict_emotion_intensity(text, model, tokenizer, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(text, padding=True, truncation=True, max_length=240, return_tensors=\"pt\")\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        \n",
    "        # Get model predictions\n",
    "        outputs = model(**inputs)\n",
    "        preds = outputs.logits.squeeze(-1)\n",
    "\n",
    "        preds = preds.cpu().numpy()\n",
    "        \n",
    "    return preds\n",
    "\n",
    "emotions = ['anger', 'fear', 'sadness', 'joy']\n",
    "optimum_model_number = ['2', '2', '3', '3']\n",
    "\n",
    "for emotion, number in tqdm(zip(emotions, optimum_model_number)):\n",
    "    state = torch.load(f'models/emotion_models/{emotion}/model_epoch_{number}.pt')\n",
    "    model.load_state_dict(state)\n",
    "    politician_tweet_df[emotion + '_intensity'] = politician_tweet_df['text'].apply(lambda x: predict_emotion_intensity(x, model, tokenizer, device))\n",
    "    politician_tweet_df[emotion + '_intensity'] = politician_tweet_df[emotion + '_intensity'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved the resulting model to ```cleaned_intensity_dataset.csv```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politician_tweet_df.to_csv(\"cleaned_intensity_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
